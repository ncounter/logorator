# logorator
A log grinder to extract statistics and more

1. a backend python log grinder to analyze, extract and compute information
2. a web dashboard to view results from the backend analysis



# What it does

## Hit URLs statistics
It analyzes Tomcat log files of your web app extracting **distinct URLs** and the **count visit** for each into a JSON `key:value` file format for `url:visit_count`

The output for this section is generated by [`count_urls.py`](https://github.com/ncounter/logorator/blob/master/backend/count_urls.py) and it will look like:
```
[
  {"/my/url/path/normally_viewed" : 194},
  {"/my/url/path/frequently_viewed" : 3958},
  {"/my/url/path/seldom_viewed" : 3},
  ...
]
```

## Hit URLs statistics from a given list of routes
It behaves the same as above in [Hit URLs statistics](https://github.com/ncounter/logorator#hit-urls-statistics) but it shows the counting of the given list of routes instead.

The output for this section is generated by [`known_urls.py`](https://github.com/ncounter/logorator/blob/master/backend/known_urls.py) and it will look like a simple list of URL strings:
```
[
  "/my/url/path/normally_viewed",
  "/my/url/path/frequently_viewed",
  "/my/url/path/seldom_viewed",
  ...
]
```
*Note: this section relies on the output of the [`count_urls.py`](https://github.com/ncounter/logorator/blob/master/backend/count_urls.py) as well, because the matching of the list of known URLs and the counting from the stats is built on the frontend side.


## Most frequent patterns from-to URLs
Decode most frequent patterns of a typical workflow generating object of a *from-to* pair of urls.

The generated output will look like:
```
[
  {
    "from" : "/my/url/path/from_page",
    "to" : "/my/url/path/to_page",
    "count": 125
  },
  {
    "from" : "/my/url/path/from_another_page",
    "to" : "/my/url/path/to_another_page",
    "count": 83
  },
  ...
]
```


# How to use

## Get the source project
```
git clone git@github.com:ncounter/logorator.git
cd logorator
```


## Configuration
You may want to configure parameters in the `logorator.conf` file first.

```
tomcat_log_path=<TOMCAT_LOGS_PATH>
stats_file=./dashboard/public/stats.json
pattern_file=./dashboard/public/patterns.json
```
**Important**: changing location of files within this application, `stats_file` for instance, will make the **dashboard** web page unable to load data. Please make sure you will update the `json source file name` accordingly for each page.


## Backend: python analyzer

### Important
The `count_urls.py` program makes an assumption about your [log format](https://github.com/ncounter/logorator/blob/master/backend/utils.py#L14) expecting log lines with **the request** information containing the **url** wrapped between `""`, something like the following:

`192.168.1.101 - - [19/Oct/2017:11:00:16 +0200] "POST /my/url/path HTTP/1.1" 200 334`

The `elaborate_patterns.py` relies on more than one assumption instead:
- the `ip` address
- the `date and time` format
- the `url`

The `known_urls.py` relies on the output of `count_urls.py` and on the output it generates itself from a given `.xml` map files with
```
  <action-mappings>
    <action path=""></action>
  </action-mappings>
```
element tags for the list of known routes.

### Running

#### Everything in one shot
```
cd logorator
python backend/logorator.py
```

*Note: in case you miss to populate some `configuration parameter` values, the related elaboration will not be executed"


## Frontend: dashboard web page

Available pages:
- Raw Stats - *How many times your urls have been hitten?* [[see here](https://github.com/ncounter/logorator#hit-urls-statistics)]
- Known route Stats - *Which known routes have been hit the most, and which never?* [[see here](https://github.com/ncounter/logorator#hit-urls-statistics-from-a-given-list-of-routes)]
- Raw Patterns - *Frequent patterns workflow* [[see here](https://github.com/ncounter/logorator#most-frequent-patterns-from-to-urls)]

### Requirements

1. Nodejs
2. Yarn

### Running
```
cd logorator/dashboard
yarn install
yarn start
```
